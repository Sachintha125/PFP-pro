{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import Node2Vec\n",
    "import sys\n",
    "\n",
    "# Specify the directory path for ppi networks of different sp\n",
    "directory_path = 'D:\\\\year 4\\\\semester 1\\\\BT\\\\BT 4033\\\\ppi_part\\\\sp_vise_ppi_networks\\\\'\n",
    "\n",
    "# Get a list of all file names in the directory\n",
    "file_list = os.listdir(directory_path)\n",
    "\n",
    "# Filter out directories (if you only want files)\n",
    "file_list = [f for f in file_list if os.path.isfile(os.path.join(directory_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    file_path = directory_path + file   # create full absolute file path\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    #passing index for each node\n",
    "    col1 = df['protein1'].to_list()\n",
    "    col2 = df['protein2'].to_list()\n",
    "    full_list = col1 + col2\n",
    "    unique_list = list(dict.fromkeys(full_list))    # unique proteins in ppi file\n",
    "\n",
    "    ind2node = {index: item for index, item in enumerate(unique_list)}  # index to protien dict \n",
    "    node2ind = {v: k for k, v in ind2node.items()}  # protein to index dict \n",
    "\n",
    "    df['protein1'] = df['protein1'].map(node2ind)\n",
    "    df['protein2'] = df['protein2'].map(node2ind)\n",
    "\n",
    "    # prepare interaction to be used as COO format\n",
    "    first_prot = df['protein1'].to_list()   \n",
    "    second_prot = df['protein2'].to_list()\n",
    "\n",
    "    print(\"List of numbers for Column 1:\", first_prot)\n",
    "    print(\"List of numbers for Column 2:\", second_prot)\n",
    "\n",
    "    # Step 1: Convert the interaction data into COO format (edge_index)\n",
    "    # COO format requires edge_index, a 2xN matrix where each column represents an edge (interaction)\n",
    "    edge_index = torch.tensor([first_prot, second_prot], dtype=torch.long)\n",
    "\n",
    "    # Step 2: Create a PyTorch Geometric Data object\n",
    "    # Assuming that all nodes are connected by edges in edge_index, we set num_nodes to the maximum node number.\n",
    "    # num_nodes = max(max(list1), max(list2)) +1   # Adding 1 because node indices are 0-based\n",
    "    data = Data(edge_index=edge_index)\n",
    "\n",
    "    # Check if CUDA is available\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # Initialize Node2Vec model\n",
    "    embedding_dim = 40  # Example embedding size\n",
    "    node2vec = Node2Vec(\n",
    "        edge_index=data.edge_index.to(device),\n",
    "        embedding_dim=embedding_dim,\n",
    "        walk_length=10, # rnadom walk length\n",
    "        context_size=10,    # window size for skip-gram model\n",
    "        walks_per_node=10,\n",
    "        p=1,    # exploration parameter\n",
    "        q=2,    # return paramter\n",
    "        sparse=True).to(device)\n",
    "\n",
    "    num_workers = 4 if sys.platform == 'linux' else 0\n",
    "    loader = node2vec.loader(batch_size=64, shuffle=True, num_workers=num_workers)\n",
    "    optimizer = torch.optim.SparseAdam(list(node2vec.parameters()), lr=0.01)\n",
    "\n",
    "    # training loop function\n",
    "    def train():\n",
    "        node2vec.train()\n",
    "        total_loss = 0\n",
    "        for pos_rw, neg_rw in loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = node2vec.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        return total_loss / len(loader)\n",
    "    \n",
    "    # model training \n",
    "    for epoch in range(1, 100):\n",
    "        loss = train()\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "    \n",
    "    node_embeddings = node2vec().detach().cpu().numpy() # node2vec embeddings \n",
    "\n",
    "    # assign generated embeddings for respective protein and save \n",
    "    node_embedding_df = pd.DataFrame(columns=['protein', 'index', 'embedding'])\n",
    "    node_embedding_df['protein'] = ind2node.values()\n",
    "    node_embedding_df['index'] = ind2node.keys()\n",
    "    node_embedding_df['embedding'] = node_embedding_df['index'].map(lambda idx: node_embeddings[idx])\n",
    "    node_embedding_df = node_embedding_df[['protein', 'embedding']]\n",
    "\n",
    "    node_embedding_df.to_csv('node2vec_embeddings.tsv', sep='\\t', index=False, header=False, mode='a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppi_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
