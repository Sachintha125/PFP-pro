{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import torch \n",
    "import pickle\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "# from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import GAE, VGAE\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "# from torch_geometric.utils import negative_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec embeddings for all plant proteins \n",
    "with open('node2vec_embedding_dict.pkl', 'rb') as f:\n",
    "    node2vec_embeddings = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing interaccting proteins as 2 lists . first list interact with second list \n",
    "with open('first_prot.pkl', 'rb') as f:\n",
    "    first_prot = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open('second_prot.pkl', 'rb') as f:\n",
    "    second_prot = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## total number of interacting proteins \n",
    "unique_list = list(dict.fromkeys(first_prot + second_prot))\n",
    "len(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## assigning index for each  protein to encode \n",
    "ind2node = {index: item for index, item in enumerate(unique_list)} # index to protein mapping \n",
    "node2ind = {v: k for k, v in ind2node.items()}  # protein to index mapping \n",
    "ind2node = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded version of both protein lists \n",
    "first_prot = [node2ind[protein] for protein in first_prot] \n",
    "second_prot = [node2ind[protein] for protein in second_prot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert the interaction data into COO format (edge_index)\n",
    "# COO format requires edge_index, a 2xN matrix where each column represents an edge (interaction)\n",
    "edge_index = torch.tensor([first_prot, second_prot], dtype=torch.long)\n",
    "\n",
    "first_prot = None\n",
    "second_prot = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial node features\n",
    "init_node_features = [node2vec_embeddings[protein] for protein in node2ind.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_node_features = torch.tensor(init_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a PyTorch Geometric Data object\n",
    "data = Data(edge_index=edge_index, x= init_node_features)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.randint(0, 1000, (2, 50000)) \n",
    "init_node_features = torch.rand(1000, 35)\n",
    "data = Data(edge_index=edge_index, x= init_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RandomLinkSplit(is_undirected=True, num_val=0, num_test=0.1, split_labels=True, add_negative_train_samples= False)\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1000, 35], edge_index=[2, 44990], pos_edge_label=[22495], pos_edge_label_index=[2, 22495])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1000, 35], edge_index=[2, 44990], pos_edge_label=[2499], pos_edge_label_index=[2, 2499], neg_edge_label=[2499], neg_edge_label_index=[2, 2499])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.to(device)\n",
    "test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_neg_edge_index = train_data.neg_edge_label_index\n",
    "# # val_neg_edge_index = val_data.neg_edge_label_index.to(device)\n",
    "# test_neg_edge_index = test_data.neg_edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## graph sage model class\n",
    "class PPIEncdoer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, mid_channel, out_channels):\n",
    "        super(PPIEncdoer, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, mid_channel) \n",
    "        self.conv2 = SAGEConv(mid_channel, out_channels)\n",
    "        self.conv_logstd = SAGEConv(mid_channel, out_channels) ##\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        # x =  self.conv2(x, edge_index)\n",
    "        # return x\n",
    "        return self.conv2(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 25 \n",
    "num_features = 35\n",
    "mid_channels = 30\n",
    "epochs = 100\n",
    "\n",
    "# model\n",
    "model = VGAE(PPIEncdoer(num_features, mid_channels,out_channels))\n",
    "\n",
    "# move to GPU \n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "GAE(\n",
      "  (encoder): PPIEncdoer(\n",
      "    (conv1): SAGEConv(35, 30, aggr=mean)\n",
      "    (conv2): SAGEConv(30, 25, aggr=mean)\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "\n",
      "Model Parameters:\n",
      "encoder.conv1.lin_l.weight: 1050 parameters\n",
      "encoder.conv1.lin_l.bias: 30 parameters\n",
      "encoder.conv1.lin_r.weight: 1050 parameters\n",
      "encoder.conv2.lin_l.weight: 750 parameters\n",
      "encoder.conv2.lin_l.bias: 25 parameters\n",
      "encoder.conv2.lin_r.weight: 750 parameters\n",
      "\n",
      "Total Parameters: 3655\n"
     ]
    }
   ],
   "source": [
    "# Manually print out the model summary\n",
    "def print_model_summary(model):\n",
    "    print(\"Model Summary:\")\n",
    "    print(model)\n",
    "    print(\"\\nModel Parameters:\")\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name}: {param.numel()} parameters\")\n",
    "        total_params += param.numel()\n",
    "    print(f\"\\nTotal Parameters: {total_params}\")\n",
    "\n",
    "print_model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_data.edge_index)\n",
    "    loss = model.recon_loss(z, train_data.pos_edge_label_index)\n",
    "    loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, test_data.edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "\n",
    "    auc, ap = test(test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n",
    "    print('Epoch: {:03d}, train loss: {:.3f}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, loss, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'VGAE_25_SAGE.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppi_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
